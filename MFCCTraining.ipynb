{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC feature extraction and Network training\n",
    "\n",
    "In this notebook you will go through an example flow of processing audio data, complete with feature extraction and training. Then we will use TFLite to quantize the model to int8 and process to be able to port it over to the MCU.\n",
    "\n",
    "Make sure you read the instructions on the exercise sheet and follow the task order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tqdm import tqdm\n",
    "\n",
    "DataSetPath = \"/Users/yannickstrumpler/Documents/Studium/MLoMCU/Lab2/hey_snips_research_6k_en_train_eval_clean_ter/\"\n",
    "\n",
    "with open(DataSetPath+\"train.json\") as jsonfile:\n",
    "    traindata = json.load(jsonfile)\n",
    "\n",
    "with open(DataSetPath+\"test.json\") as jsonfile:\n",
    "    testdata = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "\n",
    "    x_test_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    totalSliceLength = 10 # Length to stuff the signals to, given in seconds\n",
    "\n",
    "    # trainsize = len(traindata) # Number of loaded training samples\n",
    "    # testsize = len(testdata) # Number of loaded testing samples\n",
    "\n",
    "    trainsize = 1000 # Number of loaded training samples\n",
    "    testsize = 100 # Number of loaded testing samples\n",
    "\n",
    "\n",
    "    fs = 16000 # Sampling rate of the samples\n",
    "    segmentLength = 1024 # Number of samples to use per segment\n",
    "\n",
    "    sliceLength = int(totalSliceLength * fs / segmentLength)*segmentLength\n",
    "\n",
    "    for i in tqdm(range(trainsize)): \n",
    "        fs, train_sound_data = wavfile.read(DataSetPath+traindata[i]['audio_file_path']) # Read wavfile to extract amplitudes\n",
    "\n",
    "        _x_train = train_sound_data.copy() # Get a mutable copy of the wavfile\n",
    "        _x_train.resize(sliceLength) # Zero stuff the single to a length of sliceLength\n",
    "        _x_train = _x_train.reshape(-1,int(segmentLength)) # Split slice into Segments with 0 overlap\n",
    "        x_train_list.append(_x_train.astype(np.float32)) # Add segmented slice to training sample list, cast to float so librosa doesn't complain\n",
    "        y_train_list.append(traindata[i]['is_hotword']) # Read label \n",
    "\n",
    "    for i in tqdm(range(testsize)):\n",
    "        fs, test_sound_data = wavfile.read(DataSetPath+testdata[i]['audio_file_path'])\n",
    "        _x_test = test_sound_data.copy()\n",
    "        _x_test.resize(sliceLength)\n",
    "        _x_test = _x_test.reshape((-1,int(segmentLength)))\n",
    "        x_test_list.append(_x_test.astype(np.float32))\n",
    "        y_test_list.append(testdata[i]['is_hotword'])\n",
    "\n",
    "    x_train = tf.convert_to_tensor(np.asarray(x_train_list))\n",
    "    y_train = tf.convert_to_tensor(np.asarray(y_train_list))\n",
    "\n",
    "    x_test = tf.convert_to_tensor(np.asarray(x_test_list))\n",
    "    y_test = tf.convert_to_tensor(np.asarray(y_test_list))\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "3311\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "res = dict(map(lambda x: (x['worker_id'],x), traindata))\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_mfccs(tensor):\n",
    "    sample_rate = 16000.0\n",
    "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80\n",
    "    frame_length = 1024\n",
    "    num_mfcc = 13\n",
    "\n",
    "    stfts = tf.signal.stft(tensor, frame_length=frame_length, frame_step=frame_length, fft_length=frame_length)\n",
    "    spectrograms = tf.abs(stfts)\n",
    "    spectrograms = tf.reshape(spectrograms, (spectrograms.shape[0],spectrograms.shape[1],-1))\n",
    "    num_spectrogram_bins = stfts.shape[-1]\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "      num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz,\n",
    "      upper_edge_hertz)\n",
    "    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :num_mfcc]\n",
    "    return tf.reshape(mfccs, (mfccs.shape[0],mfccs.shape[1],mfccs.shape[2],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2321.47it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1868.99it/s]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_train_mfcc = compute_mfccs(x_train)\n",
    "x_test_mfcc = compute_mfccs(x_test)\n",
    "\n",
    "print(x_train_mfcc.shape)\n",
    "print(x_test_mfcc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "    totalSliceLength = 10 # Length to stuff the signals to, given in seconds\n",
    "\n",
    "    # trainsize = len(traindata) # Number of loaded training samples\n",
    "    # testsize = len(testdata) # Number of loaded testing samples\n",
    "\n",
    "    trainsize = 1000 # Number of loaded training samples\n",
    "    testsize = 100 # Number of loaded testing samples\n",
    "\n",
    "\n",
    "    fs = 16000 # Sampling rate of the samples\n",
    "    segmentLength = 1024 # Number of samples to use per segment\n",
    "\n",
    "    sliceLength = int(totalSliceLength * fs / segmentLength)*segmentLength\n",
    "    sliceLength/fs\n",
    "    \n",
    "    #Memory of a single frame: sliceLength * 32 bit (every sample is a double)\n",
    "    #Task 3: Input encoding, may be wav, mp3 etc\n",
    "    #feature transformation that amkes it easier for a network to learn good representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(x_test_mfcc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batchSize = 10\n",
    "epochs = 30\n",
    "\n",
    "train_set = (x_train_mfcc/512 + 0.5)\n",
    "train_labels = y_train\n",
    "\n",
    "test_set = (x_test_mfcc/512 + 0.5)\n",
    "test_labels = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#model.add(layers.InputLayer(input_shape=(train_set.shape[1],train_set.shape[2],train_set.shape[3]), batch_size=(batchSize)))\n",
    "model.add(layers.Conv2D(filters=3,kernel_size=(3,3),padding=\"same\",input_shape=(train_set[0].shape)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(filters=16,kernel_size=(3,3),strides=(2,2),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=32,kernel_size=(3,3),strides=(2,2),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=48,kernel_size=(3,3),padding='same',strides=(2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(8, kernel_regularizer=(regularizers.l1(0))))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.fit(train_set, y_train, batchSize, epochs, steps_per_epoch=trainsize/batchSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "score = model.evaluate(test_set, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"MFCCmodel.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFLite conversion\n",
    "#### Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_set = train_set.numpy()\n",
    "test_set = test_set.numpy()\n",
    "train_labels = train_labels.numpy()\n",
    "test_labels = test_labels.numpy()\n",
    "tflite_model_name = 'MFCC'\n",
    "# Convert Keras model to a tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "quantize = True\n",
    "if (quantize):\n",
    "    def representative_dataset():\n",
    "        for i in range(500):\n",
    "            yield([train_set[i].reshape(1,156,13,1)])\n",
    "    # Set the optimization flag.\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce full-int8 quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "    # Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function here takes in the model and outputs an header file we will import into the TFLite example project folder. (/Core/Inc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "c_model_name = 'MFCC'\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's have a look at the network we just generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tflite_interpreter = tf.lite.Interpreter(model_path=tflite_model_name + '.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next let's see how the performance of the network is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "predictions = np.zeros((len(test_set),), dtype=int)\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "for i in range(len(test_set)):\n",
    "    val_batch = test_set[i]\n",
    "    #We must convert the data into int8 format before invoking inference.\n",
    "    val_batch = val_batch / input_scale + input_zero_point\n",
    "    val_batch = np.expand_dims(val_batch, axis=0).astype(input_details[0][\"dtype\"])\n",
    "    tflite_interpreter.set_tensor(input_details[0]['index'], val_batch)\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    tflite_interpreter.invoke()\n",
    "\n",
    "    tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    #print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "    output = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions[i] = output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 100\n",
    "print(\"Accuracy of quantized to int8 model is {}%\".format(accuracy_score*100))\n",
    "print(\"Compared to float32 accuracy of {}%\".format(score[1]*100))\n",
    "print(\"We have a change of {}%\".format((accuracy_score-score[1])*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}